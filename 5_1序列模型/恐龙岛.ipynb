{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['重', '洞', '花', '走', '清', '马', '念', '家', '深', '天', '和', '以', '不', '字', '日', '助', '网', '女', '城', '是', '万', '落', '男', '根', '香', '长', '到', '李', '语', '东', '彩', '在', '观', '口', '瓜', '起', '水', '雨', '山', '田', '功', '成', '白', '为', '秀', '张', '丽', '红', '春', '事', '化', '十', '有', '居', '暖', '拔', '忘', '热', '安', '路', '心', '下', '无', '业', '罗', '千', '来', '别', '前', '灯', '绿', '地', '风', '开', '乐', '里', '结', '一', '自', '生', '由', '流', '火', '人', '军', '再', '\\n', '往', '苗', '手', '鸟']\n共计有149个字符，唯一字符有91个\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import cllm_utils\n",
    "\n",
    "# 获取名称\n",
    "data = open(\"dinos.txt\", \"r\", encoding='utf-8').read()\n",
    "\n",
    "# 转化为小写字符\n",
    "data = data.lower()\n",
    "\n",
    "# 转化为无序且不重复的元素列表\n",
    "chars = list(set(data))\n",
    "\n",
    "# 获取大小信息\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "\n",
    "print(chars)\n",
    "print(\"共计有%d个字符，唯一字符有%d个\"%(data_size,vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, '一': 1, '万': 2, '下': 3, '不': 4, '业': 5, '东': 6, '为': 7, '丽': 8, '乐': 9, '事': 10, '人': 11, '以': 12, '再': 13, '军': 14, '别': 15, '到': 16, '前': 17, '功': 18, '助': 19, '化': 20, '十': 21, '千': 22, '口': 23, '和': 24, '在': 25, '地': 26, '城': 27, '天': 28, '女': 29, '字': 30, '安': 31, '家': 32, '居': 33, '山': 34, '开': 35, '张': 36, '彩': 37, '往': 38, '心': 39, '忘': 40, '念': 41, '成': 42, '手': 43, '拔': 44, '无': 45, '日': 46, '春': 47, '是': 48, '暖': 49, '有': 50, '李': 51, '来': 52, '根': 53, '水': 54, '洞': 55, '流': 56, '深': 57, '清': 58, '火': 59, '灯': 60, '热': 61, '瓜': 62, '生': 63, '田': 64, '由': 65, '男': 66, '白': 67, '秀': 68, '红': 69, '结': 70, '绿': 71, '网': 72, '罗': 73, '自': 74, '花': 75, '苗': 76, '落': 77, '观': 78, '语': 79, '走': 80, '起': 81, '路': 82, '里': 83, '重': 84, '长': 85, '雨': 86, '风': 87, '香': 88, '马': 89, '鸟': 90}\n{0: '\\n', 1: '一', 2: '万', 3: '下', 4: '不', 5: '业', 6: '东', 7: '为', 8: '丽', 9: '乐', 10: '事', 11: '人', 12: '以', 13: '再', 14: '军', 15: '别', 16: '到', 17: '前', 18: '功', 19: '助', 20: '化', 21: '十', 22: '千', 23: '口', 24: '和', 25: '在', 26: '地', 27: '城', 28: '天', 29: '女', 30: '字', 31: '安', 32: '家', 33: '居', 34: '山', 35: '开', 36: '张', 37: '彩', 38: '往', 39: '心', 40: '忘', 41: '念', 42: '成', 43: '手', 44: '拔', 45: '无', 46: '日', 47: '春', 48: '是', 49: '暖', 50: '有', 51: '李', 52: '来', 53: '根', 54: '水', 55: '洞', 56: '流', 57: '深', 58: '清', 59: '火', 60: '灯', 61: '热', 62: '瓜', 63: '生', 64: '田', 65: '由', 66: '男', 67: '白', 68: '秀', 69: '红', 70: '结', 71: '绿', 72: '网', 73: '罗', 74: '自', 75: '花', 76: '苗', 77: '落', 78: '观', 79: '语', 80: '走', 81: '起', 82: '路', 83: '里', 84: '重', 85: '长', 86: '雨', 87: '风', 88: '香', 89: '马', 90: '鸟'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = {ch:i for i, ch in enumerate(sorted(chars))}\n",
    "ix_to_char = {i:ch for i, ch in enumerate(sorted(chars))}\n",
    "\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    \"\"\"\n",
    "    使用maxValue来修剪梯度\n",
    "    \n",
    "    参数：\n",
    "        gradients -- 字典类型，包含了以下参数：\"dWaa\", \"dWax\", \"dWya\", \"db\", \"dby\"\n",
    "        maxValue -- 阈值，把梯度值限制在[-maxValue, maxValue]内\n",
    "        \n",
    "    返回：\n",
    "        gradients -- 修剪后的梯度\n",
    "    \"\"\"\n",
    "    # 获取参数\n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n",
    "    \n",
    "    # 梯度修剪\n",
    "    for gradient in [dWaa, dWax, dWya, db, dby]:\n",
    "        np.clip(gradient, -maxValue, maxValue, out=gradient)\n",
    "\n",
    "    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "    \"\"\"\n",
    "    根据训练好的model参数parameters，实际生成字符序列，第一个字符被初始化为全0的‘虚’编码投进去\n",
    "    停止的条件是产生换行符或者生成的长度.50（设定的），实际上最终的就是参数。\n",
    "    参数：\n",
    "        parameters -- 包含了Waa, Wax, Wya, by, b的字典\n",
    "        char_to_ix -- 字符映射到索引的字典,用于生成序列的最后加\\n以及循环停止条件\n",
    "        seed -- 随机种子        \n",
    "    返回：\n",
    "        indices -- 包含采样字符索引的长度为n的列表。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从parameters 中获取参数\n",
    "    Waa, Wax, Wya, by, ba = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['ba']\n",
    "    vocab_size = by.shape[0]  # 也是输入字典的长度 // 2\n",
    "    n_a = Waa.shape[1]        # 隐层单元的数量\n",
    "    \n",
    "    # 步骤1 \n",
    "    ## 创建独热向量x，初始化为0，后续会根据输出将其设置为独热编码，即被预测值的索引的位置为1\n",
    "    x = np.zeros((vocab_size,1))\n",
    "    \n",
    "    ## 使用0初始化a_prev记忆值\n",
    "    a_prev = np.zeros((n_a,1))\n",
    "    \n",
    "    # 创建索引的空列表，这是包含要生成的字符的索引的列表。\n",
    "    indices = []\n",
    "    \n",
    "    # IDX是检测换行符的标志，我们将其初始化为-1。\n",
    "    idx = -1\n",
    "    \n",
    "    # 循环遍历时间步骤t。在每个时间步中，从概率分布中抽取一个字符，\n",
    "    # 并将其索引附加到“indices”上，如果我们达到50个字符，\n",
    "    #（我们应该不太可能有一个训练好的模型），我们将停止循环，这有助于调试并防止进入无限循环\n",
    "    counter = 0  # 控制随机数种子\n",
    "    newline_character = char_to_ix[\"\\n\"]  # 换行符的索引\n",
    "    \n",
    "    while (idx != newline_character and counter < 20):  # 没有检测到换行符并且单词长度小于50\n",
    "        # 步骤2：使用公式1、2、3进行前向传播\n",
    "        a = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + ba)  # 下一个时间步的记忆\n",
    "        z = np.dot(Wya, a) + by\n",
    "        y = cllm_utils.softmax(z)  # 根据输入来预测输出\n",
    "        \n",
    "        # 设定随机种子\n",
    "        np.random.seed(counter + seed)\n",
    "        \n",
    "        # 步骤3：根据概率分布，返回最大概率对应的概率索引\n",
    "        idx = np.random.choice(list(range(vocab_size)), p=y.ravel())\n",
    "        \n",
    "        # 添加到索引中\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # 步骤4:将输入字符重写为与采样索引对应的字符。\n",
    "        x = np.zeros((vocab_size,1))\n",
    "        x[idx] = 1\n",
    "        \n",
    "        # 更新a_prev为a\n",
    "        a_prev = a \n",
    "        \n",
    "        # 累加器\n",
    "        seed += 1\n",
    "        counter +=1\n",
    "    \n",
    "    if(counter == 20):\n",
    "        indices.append(char_to_ix[\"\\n\"])\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "    执行训练模型的单步优化，即一个单词序列对应的索引-->单样本整个时间步的训练\n",
    "    \n",
    "    参数：\n",
    "        X -- 整数列表，其中每个整数映射到词汇表中的字符。\n",
    "        Y -- 整数列表，与X完全相同，但向左移动了一个索引。\n",
    "        a_prev -- 上一个记忆\n",
    "        parameters --   权重、偏置字典，包含了以下参数：\n",
    "                        Wax -- 权重矩阵乘以输入，维度为(n_a, n_x)\n",
    "                        Waa -- 权重矩阵乘以隐藏状态，维度为(n_a, n_a)\n",
    "                        Wya -- 隐藏状态与输出相关的权重矩阵，维度为(n_y, n_a)\n",
    "                        b -- 偏置，维度为(n_a, 1)\n",
    "                        by -- 隐藏状态与输出相关的权重偏置，维度为(n_y, 1)\n",
    "        learning_rate -- 模型学习的速率    \n",
    "    返回：\n",
    "        loss -- 损失函数的值（交叉熵损失）\n",
    "        gradients -- 字典，包含了以下参数：\n",
    "                        dWax -- 输入到隐藏的权值的梯度，维度为(n_a, n_x)\n",
    "                        dWaa -- 隐藏到隐藏的权值的梯度，维度为(n_a, n_a)\n",
    "                        dWya -- 隐藏到输出的权值的梯度，维度为(n_y, n_a)\n",
    "                        db -- 偏置的梯度，维度为(n_a, 1)\n",
    "                        dby -- 输出偏置向量的梯度，维度为(n_y, 1)\n",
    "        a[len(X)-1] -- 最后的隐藏状态，维度为(n_a, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 前向传播\n",
    "    loss, cache = cllm_utils.rnn_forward(X, Y, a_prev, parameters)\n",
    "    \n",
    "    # 反向传播\n",
    "    gradients, a = cllm_utils.rnn_backward(X, Y, parameters, cache)\n",
    "    \n",
    "    # 梯度修剪，[-5 , 5]\n",
    "    gradients = clip(gradients,5)\n",
    "    \n",
    "    # 更新参数\n",
    "    parameters = cllm_utils.update_parameters(parameters,gradients,learning_rate)\n",
    "    \n",
    "    return loss, gradients, a[len(X)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(data, ix_to_char, char_to_ix, num_iterations=3500, \n",
    "          n_a=50, dino_names=7,vocab_size=27):\n",
    "    \"\"\"\n",
    "    训练模型并生成恐龙名字\n",
    "    \n",
    "    参数：\n",
    "        data -- 语料库\n",
    "        ix_to_char -- 索引映射字符字典\n",
    "        char_to_ix -- 字符映射索引字典\n",
    "        num_iterations -- 迭代次数\n",
    "        n_a -- RNN隐层单元数量\n",
    "        dino_names -- 生成恐龙名字的数量\n",
    "        vocab_size -- 在文本中的唯一字符的数量\n",
    "    \n",
    "    返回：\n",
    "        parameters -- 学习后了的参数\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从vocab_size中获取n_x、n_y\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "    \n",
    "    # 初始化参数\n",
    "    parameters = cllm_utils.initialize_parameters(n_a, n_x, n_y)\n",
    "    \n",
    "    # 初始化损失-->一个实数\n",
    "    loss = cllm_utils.get_initial_loss(vocab_size, dino_names)\n",
    "    \n",
    "    # 构建恐龙名称列表\n",
    "    with open(\"dinos2.txt\", encoding='utf-8') as f:\n",
    "            examples = f.readlines()\n",
    "            examples = [x.lower().strip() for x in examples]\n",
    "\n",
    "        # 打乱全部的恐龙名称，返回乱序的恐龙名字列表\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    # 初始化记忆为0\n",
    "    a_prev = np.zeros((n_a,1))\n",
    "    \n",
    "\n",
    "    for j in range(num_iterations):        \n",
    "        index = j % len(examples)  # 达到循环遍历的效果\n",
    "        X = [None] + [char_to_ix[ch] for ch in examples[index]]  #某单词索引列表\n",
    "        Y = X[1:] + [char_to_ix[\"\\n\"]]  # X左移构成目标索引        \n",
    "    \n",
    "        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters)\n",
    "        \"\"\"\n",
    "        每次投入一个单词对应的X、Yindex序列进行优化\n",
    "        \"\"\"       \n",
    "        \n",
    "        # 使用延迟来保持损失平滑,这是为了加速训练。\n",
    "        loss = cllm_utils.smooth(loss, curr_loss)\n",
    "        \n",
    "        # 每2000次迭代，通过sample()生成“\\n”字符，检查模型是否学习正确\n",
    "        if j % 3000 == 0:\n",
    "            print(\"第\" + str(j+1) + \"次迭代，损失值为：\" + str(loss))\n",
    "            \n",
    "            seed = 0\n",
    "            for name in range(dino_names):\n",
    "                # 采样\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed)\n",
    "                cllm_utils.print_sample(sampled_indices, ix_to_char)\n",
    "                \n",
    "                # 为了得到相同的效果，随机种子+1\n",
    "                seed += 1\n",
    "            \n",
    "            print(\"\\n\")\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6c091d8eddc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#开始训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix_to_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_to_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15360\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#结束时间\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-1485b12c3893>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(data, ix_to_char, char_to_ix, num_iterations, n_a, dino_names, vocab_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 达到循环遍历的效果\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#某单词索引列表\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# X左移构成目标索引\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-1485b12c3893>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 达到循环遍历的效果\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#某单词索引列表\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# X左移构成目标索引\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 't'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#开始时间\n",
    "start_time = time.clock()\n",
    "\n",
    "#开始训练\n",
    "parameters = model(data, ix_to_char, char_to_ix, num_iterations=15360)\n",
    "\n",
    "#结束时间\n",
    "end_time = time.clock()\n",
    "\n",
    "#计算时差\n",
    "minium = end_time - start_time\n",
    "\n",
    "print(\"执行了：\" + str(int(minium / 60)) + \"分\" + str(int(minium%60)) + \"秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
