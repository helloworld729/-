{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 一个时间步的前向\n",
    "def rnn_cell_forward(xt, a_prev, parameters):\n",
    "    \"\"\"\n",
    "    多样本单步传播\n",
    "    :param xt: 输入矩阵（每一列表示表示一个单词）\n",
    "    :param a_prev: 记忆值\n",
    "    :param parameters: 权重和偏置参数\n",
    "    :return: 生成的记忆、预测，缓存（两个记忆、输入、parameters）\n",
    "    \"\"\"\n",
    "\n",
    "    waa = parameters['waa']\n",
    "    wax = parameters['wax']\n",
    "    ba  = parameters['ba']\n",
    "    wya = parameters['wya']\n",
    "    by  = parameters['by']\n",
    "\n",
    "    a_next = np.tanh(np.dot(waa, a_prev) + np.dot(wax, xt) + ba)\n",
    "    y_pred = rnn_utils.softmax(np.dot(wya, a_next) + by)\n",
    "\n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "\n",
    "    return a_next, y_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_next =  [[ 0.95442347 -0.97959841 -0.77682357 -0.85960496  0.2996283  -0.72828789\n",
      "   0.70341981  0.396781    0.64215271 -0.68720152]\n",
      " [-0.77817006 -0.96939535 -0.90158668 -0.89269334 -0.94794605 -0.62569074\n",
      "  -0.7847199   0.73807292  0.40638533 -0.49874722]\n",
      " [ 0.34337788 -0.99997631 -0.99692205 -0.98133709 -0.93123291 -0.99802557\n",
      "  -0.99662894 -0.93641136 -0.25153222  0.54770565]\n",
      " [-0.85404662  0.97190276  0.60516394  0.65999969 -0.68038654  0.09222782\n",
      "   0.34729991  0.41705046 -0.44431726  0.74395075]\n",
      " [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978\n",
      "  -0.18887155  0.99815551  0.6531151   0.82872037]]\n",
      "a_next.shape =  (5, 10)\n",
      "yt_pred= [[0.0111839  0.98317979 0.78859101 0.63182533 0.01011613 0.11054788\n",
      "  0.63079776 0.0033688  0.0017441  0.82253474]\n",
      " [0.9888161  0.01682021 0.21140899 0.36817467 0.98988387 0.88945212\n",
      "  0.36920224 0.9966312  0.9982559  0.17746526]]\n",
      "yt_pred.shape =  (2, 10)\n"
     ]
    }
   ],
   "source": [
    "# 测试函数模块\n",
    "np.random.seed(1)\n",
    "xt = np.random.randn(3,10)\n",
    "a_prev = np.random.randn(5,10)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wax = np.random.randn(5,3)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"waa\": Waa, \"wax\": Wax, \"wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)\n",
    "print(\"a_next = \", a_next)\n",
    "print(\"a_next.shape = \", a_next.shape)\n",
    "print(\"yt_pred=\", yt_pred)\n",
    "print(\"yt_pred.shape = \", yt_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 整个时间序列\n",
    "def rnn_forward(x, a0, parameters):\n",
    "    \"\"\"\n",
    "    根据图3来实现循环神经网络的前向传播\n",
    "    \n",
    "    参数：\n",
    "        x -- 输入的全部数据，维度为(n_x, m, T_x)\n",
    "        a0 -- 初始化隐藏状态，维度为 (n_a, m)\n",
    "        parameters -- 字典，包含了以下内容:\n",
    "                        Wax -- 矩阵，输入乘以权重，维度为（n_a, n_x）\n",
    "                        Waa -- 矩阵，隐藏状态乘以权重，维度为（n_a, n_a）\n",
    "                        Wya -- 矩阵，隐藏状态与输出相关的权重矩阵，维度为（n_y, n_a）\n",
    "                        ba  -- 偏置，维度为（n_a, 1）\n",
    "                        by  -- 偏置，隐藏状态与输出相关的偏置，维度为（n_y, 1）\n",
    "    \n",
    "    返回：\n",
    "        a -- 所有时间步的隐藏状态，维度为(n_a, m, T_x)\n",
    "        y_pred -- 所有时间步的预测，维度为(n_y, m, T_x)\n",
    "        caches -- 为反向传播的保存的元组，维度为（【列表类型】cache, x)）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化“caches”，它将以列表类型包含所有的cache\n",
    "    caches = []\n",
    "    \n",
    "    # 获取 x 与 Wya 的维度信息\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters['wya'].shape\n",
    "    \n",
    "    # 使用0来初始化“a” 与“y”\n",
    "    a = np.zeros([n_a, m, T_x])\n",
    "    y_pred = np.zeros([n_y, m, T_x])\n",
    "    \n",
    "    # 初始化“next”\n",
    "    a_next = a0\n",
    "    \n",
    "    # 遍历所有时间步\n",
    "    for t in range(T_x):\n",
    "        ## 1.使用rnn_cell_forward函数来更新“next”隐藏状态与cache。\n",
    "        a_next, yt_pred, cache = rnn_cell_forward(x[:, :, t], a_next, parameters)\n",
    "        \n",
    "        ## 2.使用 a 来保存“next”隐藏状态（第 t ）个位置。\n",
    "        a[:, :, t] = a_next\n",
    "        \n",
    "        ## 3.使用 y 来保存预测值。\n",
    "        y_pred[:, :, t] = yt_pred\n",
    "        \n",
    "        ## 4.把cache保存到“caches”列表中。\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # 保存反向传播所需要的参数\n",
    "    caches = (caches, x)\n",
    "    \n",
    "    return a, y_pred, caches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a[4][1] =  [-0.95646207  0.93390825 -0.2461967   0.98521248]\n",
      "a.shape =  (5, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(3,2,4)  # 输入层维度为3， 2个样本， 每个样本4个单词\n",
    "a0 = np.random.randn(5,2)  # 时间片矩阵信息\n",
    "Waa = np.random.randn(5,5)\n",
    "Wax = np.random.randn(5,3)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"waa\": Waa, \"wax\": Wax, \"wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a, y_pred, caches = rnn_forward(x, a0, parameters)\n",
    "print(\"a[4][1] = \", a[4][1])  # 第四个隐层单元对应的第一个样本的四个时间片记忆【隐层单元 样本 时间片】\n",
    "print(\"a.shape = \", a.shape)\n",
    "# print(\"y_pred[1][3] =\", y_pred[1][3])\n",
    "# print(\"y_pred.shape = \", y_pred.shape)\n",
    "# print(\"caches[1][1][3] =\", caches[1][1][3])\n",
    "# print(\"len(caches) = \", len(caches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
